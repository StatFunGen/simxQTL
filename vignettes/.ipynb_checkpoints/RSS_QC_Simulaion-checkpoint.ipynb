{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b16d20ec-a198-417f-a76c-b561c6216954",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# RSS QC simulation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53f8007-eaf2-4669-89c8-630fd9f1f812",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Goal\n",
    "\n",
    "We want to simulate different cases where summary statistics are not consistent with the LD reference panel to bench mark our QC method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fa60b8-7f04-42a8-8ad7-86d01a1223de",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Design:\n",
    "\n",
    "We use the individual genotype, filter out the variants with high missing rate (> 0.1) or MAF < 0.05. THen we simulate the individual phenotype with different number of causal variants (1,2,3). Here the z score and LD reference are consistent. The LD reference is all from UKBB imputed data, with 50,000 randomly selected samples. For each case we simulated 500 samples from different chromosomes.\n",
    "\n",
    "### Case 1: some z scores are multiplied by a mismatch factor (Rsparse pro design)\n",
    "\n",
    "+ For z scores **other than true effect**, change 0.001, 0.01, 0.1 percent of them (miss_prop). Proportion of the z scores are changed.\n",
    "+ Change by timing a factor of 0.5, 0, -0.5, -1 (miss_frac).\n",
    "\n",
    "### Case 2: LD difference due to small sample size\n",
    "\n",
    "+ Use non-overlap 300 / 500 samples to calculate out-of sample LD reference.\n",
    "\n",
    "### Case 3: LD difference from similar but different population\n",
    "\n",
    "+ Use 1kG phase3 EUR data as LD reference. (Non-overlpaed variants are removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a79c70-eb42-40a8-a3e3-0ac8744ec1ff",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input:\n",
    "\n",
    "UKBB imputed genotype data is from `/mnt/vast/hpc/csg/xc2270/ukb_impute/LDBlock`.\n",
    "\n",
    "1000G genotype from `/mnt/vast/hpc/csg/data_public/1000G_EUR_Phase3_plink`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ef5ff6-1cdd-42a5-ad52-66022a5e860c",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Output:\n",
    "\n",
    "+ Case 1: `/home/hs3393/rss_qc/output/rsparse_pro_simudata`\n",
    "\n",
    "+ Case 2: `/home/hs3393/rss_qc/output/ukbb_simudata/result`\n",
    "    \n",
    "+ case 3: `/home/hs3393/rss_qc/output/ukbb_1000G_simudata/result`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd95ca96-cedc-4a95-b71f-257e4ea20cd4",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Simulation Detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a211a69c-0682-49a3-87f2-c75d8add5bda",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Step 1: randomly choose 500 blocks out of all LD blocks (to reduce computational time)\n",
    "\n",
    "files =  list.files(\"/mnt/vast/hpc/csg/xc2270/ukb_impute/LDBlock\", full.names = T, pattern = \"bim\")\n",
    "\n",
    "library(tidyverse)\n",
    "\n",
    "file_base = str_remove(files, \".bim\")\n",
    "\n",
    "selected_file_base = file_base[sample(length(file_base), 500)]\n",
    "\n",
    "for(base in selected_file_base){\n",
    " for(pattern in c(\".log\", \".fam\", \".bim\", \".bed\")){\n",
    "    file_name = paste0(base, pattern)\n",
    "    file.copy(from = file_name, to = str_replace(file_name, \"/mnt/vast/hpc/csg/xc2270/ukb_impute/LDBlock/\", \"/home/hs3393/rss_qc/output/simulation_data/ukbb_genotype/\"))\n",
    "    }   \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c9c83a-15be-4722-9d90-365d8444260f",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 2: Trimming the variants\n",
    "\n",
    "\n",
    "If we try to read genotype on whole LD block, that will cost super large memo. To avoid that, we can select the top 1500 variants of each PLINK file and read the smaller genotype matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f30d60-4fc7-4450-9b7d-8b25d3439a61",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#!/bin/bash -l\n",
    "# NOTE the -l flag!\n",
    "#SBATCH -t 128:00:00\n",
    "#SBATCH --mem=90000\n",
    "#SBATCH -J trim\n",
    "#SBATCH -o trim.%j.out\n",
    "#SBATCH -e trim.%j.err\n",
    "module load Plink\n",
    "\n",
    "# Define directories\n",
    "input_dir=~/rss_qc/output/simulation_data/ukbb_genotype\n",
    "output_dir=~/rss_qc/output/simulation_data/trimmed_genotype\n",
    "\n",
    "\n",
    "mkdir -p \"$output_dir\"\n",
    "\n",
    "# Loop over all .bim files\n",
    "for bim_file in \"$input_dir\"/*.bim; do\n",
    "    # Extract the dataset prefix (basename without extension)\n",
    "    base=$(basename \"$bim_file\")\n",
    "    prefix=\"${base%.bim}\"\n",
    "    echo \"Processing dataset: $prefix\"\n",
    "\n",
    "    # Create a file with the first 1500 SNP IDs (from column 2 of the .bim file)\n",
    "    snp_list=\"$output_dir/${prefix}_first1500_snps.txt\"\n",
    "    head -n 1500 \"$bim_file\" | awk '{print $2}' > \"$snp_list\"\n",
    "\n",
    "    # Use PLINK2 to avoid flip\n",
    "    plink2 --bfile \"$input_dir/$prefix\" \\\n",
    "          --extract \"$snp_list\" \\\n",
    "          --make-bed \\\n",
    "          --out \"$output_dir/${prefix}_first1500\"\n",
    "\n",
    "    echo \"Finished processing $prefix\"\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37582e5-bffc-41c4-a206-9194780be41e",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Step 3: different case simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4eb3f5-eb40-4526-bdf9-6f5fdd6d4a28",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[rsparse_simulation]\n",
    "parameter: genofile = paths\n",
    "# pheno_file: give genotype file (in plink)，we can read the gentype matrix. These files are separated by TADs.\n",
    "parameter: cwd = path(\"output\")\n",
    "parameter: job_size = 30\n",
    "parameter: walltime = \"100h\"\n",
    "parameter: mem = \"120G\"\n",
    "parameter: numThreads = 2\n",
    "parameter: n_causal = 1\n",
    "# specify the number of causal variants\n",
    "parameter: miss_prop = 0.01\n",
    "parameter: h2g = 0.005\n",
    "parameter: total_h2g = True\n",
    "parameter: miss_fac = 0.5\n",
    "# specify the number of traits (phenotypes)\n",
    "parameter: container = \"\"\n",
    "input: genofile, group_by = 1\n",
    "output: f'{cwd:a}/miss_prop_{miss_prop}_miss_fac_{miss_fac}/sample_{_index}_ncausal_{n_causal}_h2g_{h2g}.rds'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R:  expand = '${ }', stdout = f\"{_output:n}.stdout\", stderr = f\"{_output:n}.stderr\", container = container \n",
    "    # Load required libraries for statistical functions, genotype operations, and data manipulation.\n",
    "    library(\"MASS\")\n",
    "    library(\"plink2R\")\n",
    "    library(\"dplyr\")\n",
    "    library(\"readr\")\n",
    "    library(\"tidyverse\")\n",
    "\n",
    "    # Load custom simulation functions:\n",
    "    # - simulate_linreg.R: functions for simulating linear regression (e.g., sim_beta_fix_variant, sim_multi_traits)\n",
    "    # - misc.R: functions for genotype matrix operations (e.g., filter_X)\n",
    "    source(\"/home/hs3393/rss_qc/code/simulate_linreg.R\")\n",
    "    source(\"/home/hs3393/rss_qc/code/misc.R\")\n",
    "\n",
    "    # Read in genotype data using plink2R's function.\n",
    "    geno <- read_plink(${_input:nr})\n",
    "\n",
    "    # Set parameters: number of causal variants and number of traits.\n",
    "    ncausal = ${n_causal}\n",
    "    ntrait = 1\n",
    "\n",
    "    # Filtering parameters: remove SNPs with high missing rate (> 0.1) and low MAF (< 0.05).\n",
    "    imiss = 0.1\n",
    "    maf = 0.05\n",
    "    Xmat = filter_X(geno$bed, imiss, maf)\n",
    "\n",
    "    # Limit the genotype matrix to a maximum of 1000 SNPs.\n",
    "    Xmat = Xmat[, c(1:min(1000, ncol(Xmat)))]\n",
    "\n",
    "    # Define all available samples and randomly select 50,000 samples.\n",
    "    all_sample = 1:nrow(Xmat)\n",
    "    in_sample = sample(all_sample, size = 50000)\n",
    "    X_insample = Xmat[in_sample[1:50000], ]\n",
    "\n",
    "    # Choose causal variant indices.\n",
    "    LD_vars = 1\n",
    "    if(ncausal == 1){\n",
    "      # For a single causal variant, randomly select one.\n",
    "      vars = sample(1:ncol(X_insample), size =  ncausal)\n",
    "    } else {\n",
    "      # For multiple causal variants, ensure low LD (correlation < 0.3) among chosen SNPs.\n",
    "      while(length(LD_vars != 0)){\n",
    "        vars = sample(1:ncol(X_insample), size =  ncausal)\n",
    "        cor_mat = cor(X_insample[,vars]) \n",
    "        LD_vars = which(colSums(abs(cor_mat) > 0.3) > 1)\n",
    "      }\n",
    "    }\n",
    "\n",
    "    # Initialize a coefficient matrix (B) for the traits.\n",
    "    B = matrix(0, nrow =  ncol(X_insample), ncol = ntrait)\n",
    "\n",
    "    # Define causal indices and simulate effect sizes (betas) for the causal variants.\n",
    "    causal_index = vars\n",
    "    beta = sim_beta_fix_variant(G = X_insample, causal_index = causal_index, is_h2g_total = FALSE)\n",
    "    B[, 1] = beta\n",
    "\n",
    "    # Identify variants with non-zero effect.\n",
    "    variant = which(B[,1] != 0)\n",
    "\n",
    "    # Simulate phenotype data based on the genotype data and effect sizes.\n",
    "    phenotype = sim_multi_traits(G =  X_insample, B = B, h2g = ${h2g}, is_h2g_total = FALSE)\n",
    "    phenotype = phenotype$P\n",
    "    X = X_insample\n",
    "    Y = phenotype\n",
    "\n",
    "    # Calculate summary statistics for the first trait.\n",
    "    trait = calculate_sumstat(X, unname(unlist(Y[,1]))) %>% \n",
    "            rename(freq = Freq, b = Beta) %>% \n",
    "            mutate(N = 50000)\n",
    "\n",
    "    # Randomly select indices to modify summary statistics based on missing proportion.\n",
    "    set.seed(123)\n",
    "    change_index = sample(nrow(trait), ${miss_prop} * nrow(trait))\n",
    "    # Ensure that causal variants are not altered.\n",
    "    change_index = setdiff(change_index, variant)\n",
    "\n",
    "    # Adjust the effect sizes for the selected non-causal variants.\n",
    "    trait_change = trait\n",
    "    trait_change$b[change_index] = ${miss_fac} * trait_change$b[change_index]\n",
    "\n",
    "    # Compute the linkage disequilibrium (LD) correlation matrix for the in-sample genotype data.\n",
    "    LD_in_sample = get_correlation(X_insample)\n",
    "\n",
    "    # Package all the generated data into a list.\n",
    "    data = list()\n",
    "    data[[\"LD\"]] = LD_in_sample\n",
    "    data[[\"sumstat_original\"]] = trait\n",
    "    data[[\"sumstat\"]] = trait_change\n",
    "    data[[\"variant\"]] = variant\n",
    "\n",
    "    # Save the final data object as an RDS file.\n",
    "    saveRDS(data, ${_output:r})                                                                                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c015c1-740e-4c83-9c9e-1d454131b8a4",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[ukbb_simulation]\n",
    "parameter: genofile = paths\n",
    "# pheno_file: give genotype file (in plink)，we can read the gentype matrix. These files are separated by TADs.\n",
    "parameter: cwd = path(\"output\")\n",
    "parameter: job_size = 30\n",
    "parameter: walltime = \"100h\"\n",
    "parameter: mem = \"120G\"\n",
    "parameter: numThreads = 2\n",
    "parameter: n_causal = 1\n",
    "parameter: out_number = 300\n",
    "# specify the number of causal variants\n",
    "parameter: h2g = 0.005\n",
    "parameter: total_h2g = True\n",
    "# specify the number of traits (phenotypes)\n",
    "parameter: container = \"\"\n",
    "input: genofile, group_by = 1\n",
    "output: f'{cwd:a}/sample_{_index}_ncausal_{n_causal}_h2g_{h2g}_out_{out_number}.rds'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R:  expand = '${ }', stdout = f\"{_output:n}.stdout\", stderr = f\"{_output:n}.stderr\", container = container \n",
    "    # Load required libraries for statistical operations, genotype handling, and data manipulation.\n",
    "    library(\"MASS\")\n",
    "    library(\"plink2R\")\n",
    "    library(\"dplyr\")\n",
    "    library(\"readr\")\n",
    "    library(\"tidyverse\")\n",
    "\n",
    "    # Source custom functions for simulation (e.g., phenotype simulation) and matrix operations (e.g., filtering missing data).\n",
    "    source(\"/home/hs3393/rss_qc/code/simulate_linreg.R\")\n",
    "    source(\"/home/hs3393/rss_qc/code/misc.R\")\n",
    "\n",
    "    # Read genotype data from the provided input file.\n",
    "    geno <- read_plink(${_input:nr})\n",
    "    # Alternative file path (commented out):\n",
    "    # geno = read_plink(\"/mnt/vast/hpc/csg/xc2270/ukb_impute/LDBlock/LD_chr1_64\")\n",
    "\n",
    "    # Set filtering criteria: remove SNPs with missing rate > 0.1 and minor allele frequency (MAF) < 0.05.\n",
    "    imiss = 0.1\n",
    "    maf = 0.05\n",
    "    Xmat = filter_X(geno$bed, imiss, maf)\n",
    "\n",
    "    # Limit the genotype matrix to at most 1000 SNPs.\n",
    "    Xmat = Xmat[, c(1:min(1000, ncol(Xmat)))]\n",
    "\n",
    "    # Define the full set of sample indices.\n",
    "    all_sample = 1:nrow(Xmat)\n",
    "    out_number = ${out_number}   # Number of out-of-sample individuals.\n",
    "    ntrait = 1                  # Number of traits to simulate.\n",
    "    ncausal = ${n_causal}       # Number of causal variants.\n",
    "\n",
    "    # Randomly sample individuals for in-sample and out-of-sample sets.\n",
    "    in_sample = sample(all_sample, size = (50000 + out_number))\n",
    "    X_insample = Xmat[in_sample[1:50000], ]\n",
    "    X_outsample = Xmat[in_sample[50001:(50000 + out_number)], ]\n",
    "\n",
    "    # Compute the linkage disequilibrium (LD) matrix for the out-of-sample genotype data.\n",
    "    LD = get_correlation(X_outsample)\n",
    "\n",
    "    # Select causal variants:\n",
    "    # If one causal variant, choose randomly; if multiple, ensure low LD (correlation < 0.3) among them.\n",
    "    LD_vars = 1\n",
    "    if(ncausal == 1){\n",
    "      vars = sample(1:ncol(X_insample), size = ncausal)\n",
    "    } else {\n",
    "      while(length(LD_vars != 0)){\n",
    "        vars = sample(1:ncol(X_insample), size = ncausal)\n",
    "        cor_mat = cor(X_insample[, vars])\n",
    "        LD_vars = which(colSums(abs(cor_mat) > 0.3) > 1)\n",
    "      }\n",
    "    }\n",
    "\n",
    "    # Initialize a coefficient matrix for the trait.\n",
    "    B = matrix(0, nrow = ncol(X_insample), ncol = ntrait)\n",
    "\n",
    "    # Define causal indices and simulate effect sizes (betas) for the causal variants.\n",
    "    causal_index = vars\n",
    "    beta = sim_beta_fix_variant(G = X_insample, causal_index = causal_index, is_h2g_total = FALSE)\n",
    "    B[, 1] = beta\n",
    "\n",
    "    # Identify the causal variant indices (non-zero effect sizes).\n",
    "    variant = which(B[,1] != 0)\n",
    "\n",
    "    # Simulate phenotype data using the in-sample genotype data and the effect size matrix.\n",
    "    phenotype = sim_multi_traits(G = X_insample, B = B, h2g = ${h2g}, is_h2g_total = FALSE)\n",
    "    phenotype = phenotype$P\n",
    "    X = X_insample\n",
    "    Y = phenotype\n",
    "\n",
    "    # Compute the LD matrix for out-of-sample data and separately for in-sample data.\n",
    "    LD = get_correlation(X_outsample)\n",
    "    LD_out_sample = LD\n",
    "    LD_in_sample = get_correlation(X_insample)\n",
    "\n",
    "    # Calculate summary statistics for the simulated phenotype:\n",
    "    # Rename columns (Freq -> freq, Beta -> b) and add sample size information.\n",
    "    trait = calculate_sumstat(X, unname(unlist(Y[,1]))) %>% \n",
    "            rename(freq = Freq, b = Beta) %>% \n",
    "            mutate(N = 50000)\n",
    "\n",
    "    # Package all relevant outputs into a list.\n",
    "    data = list()\n",
    "    data[[\"LD_in_sample\"]] = LD_in_sample\n",
    "    data[[\"LD\"]] = LD_out_sample\n",
    "    data[[\"sumstat\"]] = trait\n",
    "    data[[\"variant\"]] = variant\n",
    "\n",
    "    # Save the final data object as an RDS file.\n",
    "    saveRDS(data, ${_output:r}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708a1c92-035a-4f15-9796-b00b90a9e37c",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[ukb_1kG_simulation]\n",
    "parameter: genofile = paths\n",
    "# pheno_file: give genotype file (in plink)，we can read the gentype matrix. These files are separated by TADs.\n",
    "parameter: cwd = path(\"output\")\n",
    "parameter: job_size = 30\n",
    "parameter: walltime = \"100h\"\n",
    "parameter: mem = \"120G\"\n",
    "parameter: numThreads = 2\n",
    "parameter: n_causal = 1\n",
    "# specify the number of causal variants\n",
    "parameter: h2g = 0.005\n",
    "parameter: total_h2g = True\n",
    "# specify the number of traits (phenotypes)\n",
    "parameter: container = \"\"\n",
    "input: genofile, group_by = 1\n",
    "output: f'{cwd:a}/sample_{_index}_ncausal_{n_causal}_h2g_{h2g}_ukb_1kG.rds'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R:  expand = '${ }', stdout = f\"{_output:n}.stdout\", stderr = f\"{_output:n}.stderr\", container = container \n",
    "    # Load required libraries for statistical computations, genotype handling, and data manipulation.\n",
    "    library(\"MASS\")\n",
    "    library(\"plink2R\")\n",
    "    library(\"dplyr\")\n",
    "    library(\"readr\")\n",
    "    library(\"tidyverse\")\n",
    "\n",
    "    # Source custom functions for simulating linear regression and for additional matrix operations.\n",
    "    source(\"/home/hs3393/rss_qc/code/simulate_linreg.R\")\n",
    "    source(\"/home/hs3393/rss_qc/code/misc.R\")\n",
    "\n",
    "    # Read the primary genotype data using a file path provided by the input.\n",
    "    geno <- read_plink(${_input:nr})\n",
    "\n",
    "    # Derive the corresponding 1000G genotype file path by replacing part of the string and appending a suffix.\n",
    "    base_path = str_replace(${_input:nr}, \"trimmed_genotype\", \"1000G_trimmed_genotype\")\n",
    "    thousand_path = paste0(base_path, \"_snps_1000G\")\n",
    "    thousand_geno = read_plink(thousand_path)\n",
    "\n",
    "    # Identify intersecting variants between the two genotype datasets based on SNP IDs and matching alleles.\n",
    "    intersect_variant = left_join(geno$bim, thousand_geno$bim, by = \"V2\") %>% \n",
    "                        filter(V5.y == V5.x & V6.y == V6.x) %>% \n",
    "                        pull(V2)\n",
    "\n",
    "    # Set filtering criteria:\n",
    "    # Remove SNPs with a missing rate greater than 0.1 and with minor allele frequency (MAF) less than 0.05.\n",
    "    imiss = 0.1\n",
    "    maf = 0.05\n",
    "\n",
    "    # Filter both genotype matrices using the quality thresholds.\n",
    "    Xmat = filter_X(geno$bed, imiss, maf)\n",
    "    thousand_Xmat = filter_X(thousand_geno$bed, imiss, maf)\n",
    "\n",
    "    # Determine the final set of SNPs by intersecting column names from both filtered matrices and the intersected variants.\n",
    "    final_intersect = intersect(intersect(colnames(Xmat), colnames(thousand_Xmat)), intersect_variant)\n",
    "    Xmat = Xmat[, final_intersect]\n",
    "    thousand_Xmat = thousand_Xmat[, final_intersect]\n",
    "\n",
    "    # Further reduce the matrices to at most 1000 SNPs.\n",
    "    Xmat = Xmat[, c(1:min(1000, ncol(Xmat)))]\n",
    "    thousand_Xmat = thousand_Xmat[, c(1:min(1000, ncol(Xmat)))]\n",
    "\n",
    "    # Define sample indices and set parameters.\n",
    "    all_sample = 1:nrow(Xmat)\n",
    "    ntrait = 1                    # Number of traits to simulate.\n",
    "    ncausal = ${n_causal}         # Number of causal variants.\n",
    "\n",
    "    # Randomly sample 50,000 individuals for the in-sample dataset.\n",
    "    in_sample = sample(all_sample, size = 50000)\n",
    "    X_insample = Xmat[in_sample[1:50000], ]\n",
    "    # Compute the linkage disequilibrium (LD) matrix for the in-sample data.\n",
    "    LD_in_sample = get_correlation(X_insample)\n",
    "\n",
    "    # Select causal variants:\n",
    "    # If there's only one causal variant, randomly choose one.\n",
    "    # If multiple, repeatedly sample until the selected variants show low pairwise LD (correlation < 0.3).\n",
    "    LD_vars = 1\n",
    "    if(ncausal == 1){\n",
    "      vars = sample(1:ncol(X_insample), size = ncausal)\n",
    "    } else {\n",
    "      while(length(LD_vars != 0)){\n",
    "        vars = sample(1:ncol(X_insample), size = ncausal)\n",
    "        cor_mat = cor(X_insample[, vars])\n",
    "        LD_vars = which(colSums(abs(cor_mat) > 0.3) > 1)\n",
    "      }\n",
    "    }\n",
    "\n",
    "    # Initialize a coefficient matrix (B) for the traits.\n",
    "    B = matrix(0, nrow = ncol(X_insample), ncol = ntrait)\n",
    "\n",
    "    # Set the causal variant indices and simulate effect sizes for them.\n",
    "    causal_index = vars\n",
    "    beta = sim_beta_fix_variant(G = X_insample, causal_index = causal_index, is_h2g_total = FALSE)\n",
    "    B[, 1] = beta\n",
    "\n",
    "    # Identify the causal variant indices (those with nonzero effect sizes).\n",
    "    variant = which(B[,1] != 0)\n",
    "\n",
    "    # Simulate phenotype data using the in-sample genotype and the simulated effect sizes.\n",
    "    phenotype = sim_multi_traits(G = X_insample, B = B, h2g = ${h2g}, is_h2g_total = FALSE)\n",
    "    phenotype = phenotype$P\n",
    "    X = X_insample\n",
    "    Y = phenotype\n",
    "\n",
    "    # Compute the LD matrix for the out-of-sample dataset based on the 1000G genotype data.\n",
    "    LD = get_correlation(thousand_Xmat)\n",
    "    LD_out_sample = LD\n",
    "\n",
    "    # Calculate summary statistics for the simulated phenotype,\n",
    "    # rename columns (Freq -> freq, Beta -> b), and add the sample size.\n",
    "    trait = calculate_sumstat(X, unname(unlist(Y[,1]))) %>% \n",
    "            rename(freq = Freq, b = Beta) %>% \n",
    "            mutate(N = 50000)\n",
    "\n",
    "    # Package the LD matrices, summary statistics, and causal variant information into a list.\n",
    "    data = list()\n",
    "    data[[\"LD_in_sample\"]] = LD_in_sample\n",
    "    data[[\"LD\"]] = LD_out_sample\n",
    "    data[[\"sumstat\"]] = trait\n",
    "    data[[\"variant\"]] = variant\n",
    "\n",
    "    # Save the assembled data object to an RDS file.\n",
    "    saveRDS(data, ${_output:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9314f4b5-c58e-44e6-b72b-7872340c4c84",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Step 4: Submit the jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0e8c35-d2ee-4326-b1cd-646c88a2ac48",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250bd26f-77ab-4880-b897-9363e939b4d8",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "work_dir=\"/home/hs3393/rss_qc/output/rsparse_pro_simudata/\"\n",
    "mkdir -p ${work_dir}\n",
    "mkdir -p ${work_dir}/code\n",
    "mkdir -p ${work_dir}/log\n",
    "cd ${work_dir}/code\n",
    "\n",
    "# Create the base_script file and write the bash code into it\n",
    "cat << 'EOF' > base_script\n",
    "#!/bin/bash -l\n",
    "# NOTE the -l flag!\n",
    "#SBATCH -t 128:00:00\n",
    "#SBATCH --mem=90000\n",
    "#SBATCH -J rsp\n",
    "#SBATCH -o WORK_DIR/log/rsp.%j.out\n",
    "#SBATCH -e WORK_DIR/log/rsp.%j.err\n",
    "\n",
    "source ~/mamba_activate.sh\n",
    "\n",
    "\n",
    "sos run /home/hs3393/rss_qc/simulation/RSS_QC_Simulation.ipynb rsparse_simulation \\\n",
    "    --genofile `ls /home/hs3393/rss_qc/output/simulation_data/trimmed_genotype/*.bim` \\\n",
    "    --n_causal CAUSAL --mem 120G --h2g 0.005 --miss_fac MISSFAC --miss_prop MISSPROP \\\n",
    "    --cwd WORK_DIR/result/causal_CAUSAL\n",
    "EOF\n",
    "\n",
    "base_sh=\"base_script\"\n",
    "for miss_prop in 0.001 0.01; do\n",
    "    for miss_fac in 0.5 0 -0.5 -1; do\n",
    "            for causal in 1 2 3; do\n",
    "            output_script=\"miss_prop_${miss_prop}_miss_fac_${miss_fac}_causal_${causal}.sh\"\n",
    "            cat ${base_sh}| sed \"s|MISSPROP|${miss_prop}|g\" |sed \"s|MISSFAC|${miss_fac}|g\" |sed \"s|CAUSAL|${causal}|g\" |sed \"s|WORK_DIR|${work_dir}|g\"   > ${output_script}\n",
    "            sbatch ${output_script}\n",
    "        done\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56256200-434a-4ec9-a87f-06f3921eac91",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "### Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfa527b-9988-4edc-b29c-d3ee2020f41c",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "work_dir=\"/home/hs3393/rss_qc/output/ukbb_simudata/\"\n",
    "mkdir -p ${work_dir}\n",
    "mkdir -p ${work_dir}/code\n",
    "mkdir -p ${work_dir}/log\n",
    "cd ${work_dir}/code\n",
    "\n",
    "# Create the base_script file and write the bash code into it\n",
    "cat << 'EOF' > base_script\n",
    "#!/bin/bash -l\n",
    "# NOTE the -l flag!\n",
    "#SBATCH -t 128:00:00\n",
    "#SBATCH --mem=90000\n",
    "#SBATCH -J ukbb\n",
    "#SBATCH -o WORK_DIR/log/ukbb.%j.out\n",
    "#SBATCH -e WORK_DIR/log/ukbb.%j.err\n",
    "\n",
    "source ~/mamba_activate.sh\n",
    "\n",
    "\n",
    "sos run /home/hs3393/rss_qc/simulation/RSS_QC_Simulation.ipynb ukbb_simulation \\\n",
    "    --genofile `ls /home/hs3393/rss_qc/output/simulation_data/trimmed_genotype/*.bim` \\\n",
    "    --n_causal CAUSAL --mem 120G --h2g 0.005 --out_number OUT \\\n",
    "    --cwd WORK_DIR/result/out_number_OUT/causal_CAUSAL/\n",
    "EOF\n",
    "\n",
    "base_sh=\"base_script\"\n",
    "for out_number in 300 500 ; do\n",
    "        for causal in 1 2 3; do\n",
    "        output_script=\"out_number_${out_number}_causal_${causal}.sh\"\n",
    "        cat ${base_sh}| sed \"s|OUT|${out_number}|g\" |sed \"s|CAUSAL|${causal}|g\" |sed \"s|WORK_DIR|${work_dir}|g\"   > ${output_script}\n",
    "        sbatch ${output_script}\n",
    "    done\n",
    "done\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23859e04-04af-4574-84a4-6da8ef752e3b",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d66a9e7-9662-41d4-b3e1-fe6da30bcbab",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "work_dir=\"/home/hs3393/rss_qc/output/ukbb_1000G_simudata/\"\n",
    "mkdir -p ${work_dir}\n",
    "mkdir -p ${work_dir}/code\n",
    "mkdir -p ${work_dir}/log\n",
    "cd ${work_dir}/code\n",
    "\n",
    "# Create the base_script file and write the bash code into it\n",
    "cat << 'EOF' > base_script\n",
    "#!/bin/bash -l\n",
    "# NOTE the -l flag!\n",
    "#SBATCH -t 128:00:00\n",
    "#SBATCH --mem=90000\n",
    "#SBATCH -J UK1G\n",
    "#SBATCH -o WORK_DIR/log/UK1G.%j.out\n",
    "#SBATCH -e WORK_DIR/log/UK1G.%j.err\n",
    "\n",
    "source ~/mamba_activate.sh\n",
    "\n",
    "\n",
    "sos run /home/hs3393/rss_qc/simulation/RSS_QC_Simulation.ipynb ukb_1kG_simulation \\\n",
    "    --genofile `ls /home/hs3393/rss_qc/output/simulation_data/trimmed_genotype/*.bim` \\\n",
    "    --n_causal CAUSAL --mem 120G --h2g 0.005 \\\n",
    "    --cwd WORK_DIR/result/causal_CAUSAL\n",
    "EOF\n",
    "\n",
    "base_sh=\"base_script\"\n",
    "    for causal in 1 2 3; do\n",
    "    output_script=\"causal_${causal}.sh\"\n",
    "    cat ${base_sh}| sed \"s|CAUSAL|${causal}|g\" |sed \"s|WORK_DIR|${work_dir}|g\"   > ${output_script}\n",
    "    sbatch ${output_script}\n",
    "done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.24.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
